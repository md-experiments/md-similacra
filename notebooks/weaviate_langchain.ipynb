{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "444a3d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "import os\n",
    "\n",
    "os.chdir(os.path.abspath(os.curdir).replace('notebooks',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "83727042",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import files_in_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de125bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scene 7: The animal crew cheer and help Oliver dig, using their paws, claws, and beaks to excavate the dirt and sand. Finally, they hit something solid and metallic.\n",
      "\n",
      "Scene 8: \"It's the chest! We found it!\" Oliver yowls, jumping up and down with excitement. They open the chest with a creak, and inside they find piles of gold coins, jewels, and shiny trinkets.\n",
      "\n",
      "Scene 9: \"We did it! We found the treasure!\" Polly sings, twirling around in joy. \"And it's all thanks to our teamwork and brainwork.\"\n",
      "\n",
      "Scene 10: \"Arrr, that was a tricky map, indeed,\" Salty pants, taking a gulp of water from his bottle. \"But we cracked it like a nut!\" \n",
      "\n",
      "Scene 11: Oliver grins, feeling proud of his animal crew. They might not be real pirates, but they are definitely brave, clever, and loyal friends. \"Let's celebrate our victory with some fish and milk,\" he meows, and they all feast on their well-deserved reward.\n"
     ]
    }
   ],
   "source": [
    "# import\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Weaviate\n",
    "from langchain.document_loaders import TextLoader, JSONLoader\n",
    "import weaviate\n",
    "# load the document and split it into chunks\n",
    "loader = TextLoader(\"../data/stories/donaldson1/04_2_section_plot_prompt.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "# split it into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\\n\", \"\\n\"], chunk_size=1000, chunk_overlap=200)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# create the open-source embedding function\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "WEAVIATE_URL = 'http://localhost:8080'\n",
    "#embeddings = embedding_function.embed_documents([d.page_content for d in docs])\n",
    "# load it into Chroma\n",
    "client = weaviate.Client(url=WEAVIATE_URL)\n",
    "wv = Weaviate(client, index_name = 'test', text_key = 'body')\n",
    "db = wv.from_documents(docs, embedding_function, weaviate_url=WEAVIATE_URL, by_text=False)\n",
    "# query it\n",
    "query = \"Where are the squirrels\"\n",
    "docs = db.similarity_search(query)\n",
    "\n",
    "# print results\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01d9ca6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting jq\n",
      "  Downloading jq-1.4.1-cp39-cp39-macosx_10_9_x86_64.whl (365 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.1/365.1 kB\u001b[0m \u001b[31m626.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: jq\n",
      "Successfully installed jq-1.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install jq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fafc01d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:02<00:00, 23.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# import\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Weaviate\n",
    "from langchain.document_loaders import TextLoader, JSONLoader\n",
    "import weaviate\n",
    "from tqdm import tqdm\n",
    "ls_files = files_in_dir('./data/arxiv/clean_txt/',['.json'])\n",
    "\n",
    "# create the open-source embedding function\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "WEAVIATE_URL = 'http://localhost:8080'\n",
    "#embeddings = embedding_function.embed_documents([d.page_content for d in docs])\n",
    "# load it into Chroma\n",
    "client = weaviate.Client(url=WEAVIATE_URL)\n",
    "wv = Weaviate(client, index_name = 'rag0', text_key = 'body')\n",
    "all_docs = []\n",
    "for path in tqdm(ls_files):\n",
    "    loader = JSONLoader(path, jq_schema= '.[].body')\n",
    "    documents = loader.load()\n",
    "\n",
    "    # split it into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\\n\", \"\\n\"], chunk_size=1000, chunk_overlap=200)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    all_docs = all_docs + docs\n",
    "\n",
    "db = wv.from_documents(all_docs, embedding_function, weaviate_url=WEAVIATE_URL, by_text=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3950e8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this section, we formally deﬁne single-time retrieval-augmented generation and propose the framework of active retrieval augmented generation that decides when and what to retrieve throughout the generation.\n"
     ]
    }
   ],
   "source": [
    "# query it\n",
    "query = \"Retrieval augmented generation\"\n",
    "docs = db.similarity_search(query)\n",
    "\n",
    "# print results\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be85bdb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e53fbaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "with open('openai.key','r') as f:\n",
    "    openai_api_key = f.read()\n",
    "os.environ['OPENAI_API_KEY'] = openai_api_key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e4026c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "de7662cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain import PromptTemplate\n",
    "# Prompt\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
    "Follow any additional instructions provided in the question section when forming the answer. For instance, \"use bullet points\" or \"use simple language\".\n",
    "\n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1a70a84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qa = RetrievalQA.from_chain_type(llm=OpenAI(temperature=0, max_tokens = 1000,), \n",
    "                             chain_type=\"stuff\", \n",
    "                             retriever=db.as_retriever(),\n",
    "                             chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    "                             return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8ade351b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'in bullet points, provide examples of retrieval augmented generation setups'\n",
    "result = qa({\"query\": query})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b015d8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      "• Sparse-vector Retrieval\n",
      "• Dense-vector Retrieval\n",
      "• Task-specific Retrieval\n",
      "• Retrieval Memory\n",
      "• Data Augmentation\n",
      "• Attention Mechanism\n",
      "• Skeleton & Templates\n",
      "• Information Retrieval\n"
     ]
    }
   ],
   "source": [
    "print(result['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c28e63fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_answ = result['result'].split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "eb0934ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrieval augmented generation is a paradigm that uses sparse-vector retrieval to augment language models for downstream NLP tasks.\n",
      " Retrieval augmented generation is a framework that uses dense-vector retrieval to decide when and what to retrieve during generation.\n",
      " Retrieval augmented generation is a process of using task-specific retrieval to supplement a language model in order to generate text.\n",
      " Retrieval augmented generation is a framework that uses a retrieval memory to decide when and what to retrieve throughout the generation process.\n",
      " Retrieval Augmented Generation is a method of data augmentation that uses external information to supplement a parametric model in order to improve the performance of language models in knowledge-intensive tasks.\n",
      " Retrieval augmented generation is a paradigm that uses an attention mechanism to retrieve relevant information from external sources to improve the quality of generated text.\n",
      " Retrieval augmented generation uses skeletons and templates to retrieve relevant information from external sources to generate text.\n",
      " Retrieval Augmented Generation is a process of using Information Retrieval techniques to supplement a text generation model.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for q in ls_answ:\n",
    "    if len(q)>2:\n",
    "        query = f'in a single sentence, explain retrieval augmented generation using {q}'\n",
    "        r = qa({\"query\": query})\n",
    "        print(r['result'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c41e48d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      "• Sparse-vector Retrieval\n",
      "• Dense-vector Retrieval\n",
      "• Task-specific Retrieval\n",
      "• Retrieval Memory\n",
      "• Data Augmentation\n",
      "• Attention Mechanism\n",
      "• Skeleton & Templates\n",
      "• Information Retrieval\n"
     ]
    }
   ],
   "source": [
    "print(result['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "35385090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Retrieval augmented generation is a process where a language model (LM) is prompted to generate retrieval queries when necessary while generating an answer using retrieval-encouraging instructions, or by directly using the LM's generation as search queries. It is a simple and generic retrieval-augmented LM that actively decides when and what to retrieve throughout the generation process, and is applicable to a variety of long-form generation tasks.\""
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'Describe retrieval augmented generation'\n",
    "result = qa({\"query\": query})\n",
    "result['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2fb7d834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Text embeddings are dense vectors that represent a sequence of text tokens. They are obtained by obtaining the hidden representation of each token from the last encoding layer of a text-to-text Transformer model and then performing mean-pooling over them to get a single dense vector.'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'Describe text embeddings in simple language'\n",
    "result = qa({\"query\": query})\n",
    "result['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d0739322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Vector stores refer to the low-dimensional dense vectors that are created using BERT-based encoders and used to measure the similarity between two pieces of text. They are used in dense-vector retrieval methods to measure semantic relevance rather than lexical overlap.'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'Describe vector stores'\n",
    "result = qa({\"query\": query})\n",
    "result['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2be8797d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'seq_num': 5,\n",
       "  'source': '/Users/md/Downloads/ws/md-similacra/data/arxiv/clean_txt/gpt_pp01_2305.06983v1.json'},\n",
       " {'seq_num': 12,\n",
       "  'source': '/Users/md/Downloads/ws/md-similacra/data/arxiv/clean_txt/gpt_pp01_2202.01110v2.json'},\n",
       " {'seq_num': 2,\n",
       "  'source': '/Users/md/Downloads/ws/md-similacra/data/arxiv/clean_txt/gpt_pp01_2202.01110v2.json'},\n",
       " {'seq_num': 3,\n",
       "  'source': '/Users/md/Downloads/ws/md-similacra/data/arxiv/clean_txt/gpt_pp01_2305.06983v1.json'}]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[r.metadata for r in result['source_documents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ca6ddd0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'in bullet points, provide examples of retrieval augmented generation setups',\n",
       " 'result': ' \\n\\n• Sparse-vector Retrieval\\n• Dense-vector Retrieval\\n• Task-specific Retrieval\\n• Retrieval Memory\\n• Data Augmentation\\n• Attention Mechanism\\n• Skeleton & Templates\\n• Information Retrieval',\n",
       " 'source_documents': [Document(page_content='In this section, we formally deﬁne single-time retrieval-augmented generation and propose the framework of active retrieval augmented generation that decides when and what to retrieve throughout the generation.', metadata={'seq_num': 5, 'source': '/Users/md/Downloads/ws/md-similacra/data/arxiv/clean_txt/gpt_pp01_2305.06983v1.json'}),\n",
       "  Document(page_content='In this paper, we surveyed recent approaches for retrieval-augmented text generation. We reviewed and summarized the development of different components of retrieval-augmented text generation including retrieval metrics, retrieval sources, and integration paradigms. We gave in-depth discussions when retrieval-augmented text generation comes to different applications including dialogue response generation, machine translation, and other generation tasks. We also pointed out some future directions for retrieval-augmented text generation.', metadata={'seq_num': 12, 'source': '/Users/md/Downloads/ws/md-similacra/data/arxiv/clean_txt/gpt_pp01_2202.01110v2.json'}),\n",
       "  Document(page_content='In this section, we ﬁrst give a general formulation of retrieval-augmented text generation. Then, we discuss three major components of the retrievalaugmented generation paradigm, including the re-arXiv:2202.01110v2  [cs.CL]  13 Feb 2022 Input Sources (Sec. 2.2):Training CorpusExternal DataUnsupervised DataMetrics(Sec. 2.3):Sparse-vector RetrievalDense-vector RetrievalTask-specific RetrievalRetrieval MemoryGeneration ModelSec. 4: Machine TranslationSec. 5: Other TasksData AugmentationAttention MechanismSkeleton & TemplatesInformation RetrievalTasks:Sec. 3: Dialogue GenerationModels (Sec 2.4):OutputFigure 1: The overview of this survey.\\ntrieval source, retrieval metric and integration methods.', metadata={'seq_num': 2, 'source': '/Users/md/Downloads/ws/md-similacra/data/arxiv/clean_txt/gpt_pp01_2202.01110v2.json'}),\n",
       "  Document(page_content='We ask the following question in this paper: can we create a simple and generic retrieval-augmented LM that actively decides when and what to retrieve throughout the generation process, and are applicable to a variety of long-form generation tasks?', metadata={'seq_num': 3, 'source': '/Users/md/Downloads/ws/md-similacra/data/arxiv/clean_txt/gpt_pp01_2305.06983v1.json'})]}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f574add0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result['source_documents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d7439ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_file = './data/arxiv/tar/2009.08553v4.tax.gz'\n",
    "path_file = './data/arxiv/tar/2104.07713v2.tax.gz'\n",
    "path_folder = './data/arxiv/tar/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e1f3ccaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TarInfo 'bare_jrnl_compsoc.tex' at 0x7fe28932b4c0>\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "\n",
    "tar = tarfile.open(path_file, \"r:gz\")\n",
    "for member in tar.getmembers():\n",
    "    if member.name.endswith('.tex') and ('/' not in member.name):\n",
    "        print(member)\n",
    "        ltx = tar.extractfile(member).readlines()\n",
    "        ltx_lines = [l.decode('utf-8') for l in ltx]\n",
    "        ltx_lines = [l for l in ltx_lines if not str(l).startswith('%')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "486755b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[[Introduction}[sec:introduction}}\\n', '[Related Work}\\n', '[Conclusion}\\n']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section_names = [t for t in ltx_lines if '\\\\section' in t]\n",
    "sel_sections = ['Introduction',\n",
    "'Related Work',\n",
    "'Conclusion']\n",
    "\n",
    "sel_section_names = [s for s in section_names if any([sec in s for sec in sel_sections])]\n",
    "[remove_sometext(s) for s in sel_section_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0aa10a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = []\n",
    "for i in range(len(section_names)-1):\n",
    "    sec_start = ltx_lines.index(section_names[i])\n",
    "    sec_end = ltx_lines.index(section_names[i+1])\n",
    "    section_raw_text = ltx_lines[sec_start+1:sec_end]\n",
    "    section_text =' '.join([remove_sometext(s).replace('}',']') for s in section_raw_text if s!='\\n'])\n",
    "    sections.append(section_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3bba3c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_sometext(string):\n",
    "    pattern = r'\\\\[a-zA-Z0-9_]+{'\n",
    "    cleaned_string = re.sub(pattern, '[', string)\n",
    "    return cleaned_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "27d38274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[sec:related_work]\\n [Conventional Query Expansion]\\n \\\\ours shares some merits with query expansion (QE) methods based on pseudo relevance feedback [rocchio1971relevance,abdul2004umass,lv2010positional] in that they both expand the queries with relevant contexts (terms) without the use of external supervision. \\\\ours is superior as it expands the queries with knowledge stored in the PLMs rather than the retrieved passages and its expanded terms are learned through text generation.\\n [Recent Query Reformulation]\\n There are recent or concurrent studies [nogueira-cho-2017-task,zaiem2019sequence,yu2020few,vakulenko2020question,lin2020query] that reformulate queries with generation models for other retrieval tasks.\\n However, these studies are not easily applicable or efficient enough for OpenQA because: (1) They require external resources such as paraphrase data~[zaiem2019sequence], search sessions~[yu2020few], or conversational contexts~[lin2020query,vakulenko2020question] to form the reformulated queries, which are not available or showed inferior domain-transfer performance in OpenQA~[zaiem2019sequence];  (2) They involve time-consuming training process such as RL. For example, [nogueira-cho-2017-task] reported a training time of 8 to 10 days as it uses retrieval performance in the reward function and conducts retrieval at each iteration.\\n In contrast, \\\\ours uses freely accessible in-domain contexts like passage titles as the generation targets and standard seq2seq learning, which, despite its simplicity, is not only more efficient but effective for OpenQA.\\n [Retrieval for OpenQA] \\n Existing sparse retrieval methods for OpenQA [chen-etal-2017-reading] solely rely on the information of the questions.\\n \\\\ours extends to contexts relevant to the questions by extracting information inside PLMs and helps sparse methods achieve comparable or better performance than dense methods~[guu2020realm,karpukhin2020dense], while enjoying the simplicity and efficiency of sparse representations.\\n \\\\ours can also be used with dense representations to seek for even better performance, which we leave as future work. \\n [Generative QA]\\n Generative QA generates answers through seq2seq learning instead of extracting answer spans.\\n Recent studies on generative OpenQA [lewis2020retrieval,min2020ambigqa,izacard2020leveraging] are orthogonal to \\\\ours in that they focus on improving the reading stage and directly reuse DPR [karpukhin2020dense] as the retriever.  \\n Unlike generative QA, the goal of \\\\ours is not to generate perfect answers to the questions but pertinent contexts that are helpful for retrieval.\\n Another line in generative QA learns to generate answers without relevant passages as the evidence but solely the question itself using PLMs [roberts2020much,brown2020language]. \\n \\\\ours further confirms that one can extract factual knowledge from PLMs, which is not limited to the answers as in prior studies but also other relevant contexts.\\n'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b4c64a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "139075bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = weaviate.Client(WEAVIATE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ed97ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Describe Captain Claw',\n",
       " 'result': \" Captain Claw is a notorious pirate who has sailed the seven seas and has a reputation for being ruthless and cunning. He is always looking for treasure and will do whatever it takes to get it. He is Oliver's rival and the antagonist of the story, and is constantly trying to outsmart him.\",\n",
       " 'source_documents': [Document(page_content=\"Name: Captain Claw (10), Male Role: Captain Claw is Oliver's rival and the antagonist of the story. He tries to steal Oliver's treasure and is constantly trying to outsmart him., Bio: Captain Claw is a notorious pirate who has sailed the seven seas and has a reputation for being ruthless and cunning. He is always looking for treasure and will do whatever it takes to get it.\\n\\n\\nThis is the story so far Oliver and his animal crew set sail on a cardboard ship in search of treasure.\\nOliver and his crew face a treacherous storm at sea.\\n.\\n\\n\\nThis section is titled: The Tricky Map, with the description: Oliver and his crew must decode a map to find the buried treasure.\\nThese are the CHARACTERS MENTIONED in this scene Oliver, Polly, Salty.\\nOnly only mention characters from the list of CHARACTERS MENTIONED in this scene. Rely on their descriptions per the FULL LIST OF CHARACTERS in the story. If needed, there can be references to other characters as part of the dialogue or narration.\", metadata={'source': '../data/stories/donaldson1/04_2_section_plot_prompt.txt'}),\n",
       "  Document(page_content=\"This is FULL LIST OF CHARACTERS in the story:\\nName: Oliver (3), Male Role: Oliver is the protagonist of the story. He sets sail on a cardboard ship in search of buried treasure and faces various challenges along the way., Bio: Oliver is a mischievous cat who dreams of becoming a pirate. He is fearless and adventurous, but sometimes gets into trouble because of his impulsive nature.\\n\\nName: Polly (5), Female Role: Polly is Oliver's loyal first mate. She helps him navigate the stormy sea and encourages him when he feels discouraged., Bio: Polly is a friendly and talkative parrot who loves to sing and dance. She is always ready to help her friends and has a great sense of humor.\\n\\nName: Salty (7), Male Role: Salty is Oliver's trusty lookout. He keeps an eye out for danger and helps Oliver stay on course., Bio: Salty is a loyal and brave dog who loves to explore and sniff out new things. He is always ready to protect his friends and is very playful.\", metadata={'source': '../data/stories/donaldson1/04_2_section_plot_prompt.txt'}),\n",
       "  Document(page_content='Scene 4: \"Arrr, that makes sense,\" Salty barks, wagging his tail. \"Maybe \\'X\\' stands for \\'crossing,\\' as in crossing the palm trees or crossing the rocks!\"\\n\\nScene 5: Oliver nods, impressed by his crew\\'s ingenuity. \"Brilliant, Salty! Let\\'s try that.\" He leads the way, and the others follow him, navigating through the dense jungle and clambering over boulders and fallen logs. \\n\\nScene 6: Soon, they reach a clearing where they spot a rock formation that looks like a giant letter X. \"Look, mates! The treasure must be buried beneath it!\" Oliver exclaims, pointing at the spot.\\n\\nScene 7: The animal crew cheer and help Oliver dig, using their paws, claws, and beaks to excavate the dirt and sand. Finally, they hit something solid and metallic.\\n\\nScene 8: \"It\\'s the chest! We found it!\" Oliver yowls, jumping up and down with excitement. They open the chest with a creak, and inside they find piles of gold coins, jewels, and shiny trinkets.', metadata={'source': '../data/stories/donaldson1/04_2_section_plot_prompt.txt'}),\n",
       "  Document(page_content='You are a scriptwriter who writes and is inspired by Julia Donaldson and you write stories in their style. \\nTheir style is typically described as Engages young readers and captures their imaginations. Her writing is known for its rhythmic and rhyming patterns, enchanting storytelling, and memorable characters. She often introduces protagonists who face challenges or embark on quests, making her books both entertaining and educational. Her stories are often written in lively and catchy verse, which creates a musical quality that children find captivating.. \\n\\nThis is the story summary: \\nOliver, a mischievous cat with dreams of becoming a pirate, sets sail on a cardboard ship in search of buried treasure. Along his journey, he encounters various challenges, including a stormy sea, a friendly seagull, and a tricky map. With the help of his loyal animal crew, Oliver learns the true meaning of bravery and discovers that the greatest treasure of all is', metadata={'source': '../data/stories/donaldson1/04_2_section_plot_prompt.txt'})]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b4bf92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "similacra",
   "language": "python",
   "name": "similacra"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
